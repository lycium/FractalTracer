#pragma once

#include <atomic>
#include <vector>
#include <array>
#include <algorithm>
#include <cstring>

#include "Scene.h"
#include "HDREnvironment.h"
#include "CameraParams.h"
#include "SceneParams.h"



constexpr int noise_size = 1 << 8;
inline std::array<uint16_t, noise_size * noise_size> & getNoiseData()
{
	static std::array<uint16_t, noise_size * noise_size> data;
	return data;
}
#define noise_data (getNoiseData())


inline void HilbertFibonacci(const vec2i dx, const vec2i dy, vec2i p, int size, uint64_t & next_val)
{
	if (size > 1)
	{
		size >>= 1;
		HilbertFibonacci( dy,  dx, p, size, next_val); p += dy *  size;
		HilbertFibonacci( dx,  dy, p, size, next_val); p += dx *  size;
		HilbertFibonacci( dx,  dy, p, size, next_val); p += dx * (size - 1) - dy;
		HilbertFibonacci(-dy, -dx, p, size, next_val);
	}
	else
	{
		next_val += 11400714819323198487ull;
		noise_data[p.y() * noise_size + p.x()] = (uint16_t)(next_val >> 48);
	}
}

// From PBRT
inline double RadicalInverse(int sample, int base) noexcept
{
	const double invBase = 1.0 / base;

	int reversedDigits = 0;
	double invBaseN = 1;
	while (sample)
	{
		const int next  = sample / base;
		const int digit = sample - base * next;
		reversedDigits = reversedDigits * base + digit;
		invBaseN *= invBase;
		sample = next;
	}

	return std::min(reversedDigits * invBaseN, DoubleOneMinusEpsilon);
}


inline real uintToUnitReal(uint32_t v)
{
#if USE_DOUBLE
	constexpr double uint32_double_scale = 1.0 / (1ull << 32);
	return v * uint32_double_scale;
#else
	// Trick from MTGP: generate an uniformly distributed single precision number in [1,2) and subtract 1
	union
	{
		uint32_t u;
		float f;
	} x;
	x.u = (v >> 9) | 0x3f800000u;
	return x.f - 1.0f;
#endif
}

// https://nullprogram.com/blog/2018/07/31/
inline uint32_t lowbias32(uint32_t x)
{
	x ^= x >> 16;
	x *= 0x45d9f3bu;
	x ^= x >> 16;
	return x;
}

// Owen-scrambled Halton: random digit permutations using a per-(pixel,dim) seed
inline real haltonScrambled(uint32_t sample, int base, uint32_t seed) noexcept
{
	const double invBase = 1.0 / base;
	double result = 0;
	double frac = invBase;
	while (sample > 0)
	{
		const uint32_t digit = sample % (uint32_t)base;
		sample /= (uint32_t)base;
		seed = lowbias32(seed ^ digit);
		result += (seed % (uint32_t)base) * frac;
		frac *= invBase;
	}
	return std::min(result, DoubleOneMinusEpsilon);
}

// Advance dim counter and return the next scrambled Halton sample
inline real nextSample(int pass, int & dim, uint32_t pixel_hash) noexcept
{
	constexpr static int primes[6] = { 2, 3, 5, 7, 11, 13 };
	const int d = dim;
	dim = (d < 5) ? d + 1 : 0;
	return haltonScrambled((uint32_t)pass, primes[d], lowbias32(pixel_hash ^ ((uint32_t)d * 0x9e3779b1u)));
}

inline real wrap1r(real u, real v) { return (u + v < 1) ? u + v : u + v - 1; }

inline int wrap6i(int & v)
{
	const int o = v;
	const int u = o + 1;
	v = (u < 6) ? u : 0;
	return o;
}

inline real signum(real v) { return (v >= 0) ? (real)1 : (v == 0 ? 0 : -1); }

// Convert uniform distribution into triangle-shaped distribution
// From https://www.shadertoy.com/view/4t2SDh
inline real triDist(real v)
{
	const real orig = v * 2 - 1;
	v = orig / std::sqrt(std::fabs(orig));
	v = std::max((real)-1, v); // Nerf the NaN generated by 0*rsqrt(0). Thanks @FioraAeterna!
	v = v - signum(orig);

	return v;
}

// From Alex Evans
inline vec2r CauchyDist(const vec2r & u)
{
	const vec2r h = u * vec2r(pi * 2, pi * 0.5f);
	return vec2r(cos(h.x()), sin(h.x())) * tan(h.y());
}


struct RenderOutput
{
	int xres, yres;
	int passes = 0;

	std::vector<vec3f> beauty;
	std::vector<vec3f> normal;
	std::vector<vec3f> albedo;


	RenderOutput(int xres_, int yres_) : xres(xres_), yres(yres_)
	{
		beauty.resize(xres * yres);
		normal.resize(xres * yres);
		albedo.resize(xres * yres);
	}

	void resize(int new_xres, int new_yres)
	{
		xres = new_xres;
		yres = new_yres;
		const size_t n = (size_t)xres * yres;
		beauty.resize(n);
		normal.resize(n);
		albedo.resize(n);
		clear();
	}

	void clear()
	{
		passes = 0;
		memset((void *)&beauty[0], 0, sizeof(vec3f) * xres * yres);
		memset((void *)&normal[0], 0, sizeof(vec3f) * xres * yres);
		memset((void *)&albedo[0], 0, sizeof(vec3f) * xres * yres);
	}
};


struct ThreadControl
{
	const int num_passes;

	std::atomic<int> next_bucket = 0;
};


inline void render(
	const int x, const int y,
	const int pass,
	const CameraParams & camera, const LightParams & light, const RenderSettings & settings,
	Scene & scene, RenderOutput & output, const HDREnvironment * hdr_env) noexcept
{
	const int max_bounces = settings.max_bounces;
	const int xres = output.xres;
	const int yres = output.yres;
	const int pixel_idx = y * xres + x;

	const real aspect_ratio = xres / (real)yres;
	const real fov_rad = camera.fov_deg * two_pi / 360;
	const real sensor_width  = 2 * std::tan(fov_rad / 2);
	const real sensor_height = sensor_width / aspect_ratio;

	int dim = 0;
	const uint32_t pixel_hash = noise_data[(y % noise_size) * noise_size + (x % noise_size)];
	const vec2r pixel_u =
	{
		nextSample(pass, dim, pixel_hash),
		nextSample(pass, dim, pixel_hash)
	};
#if 1
	const vec2r pixel_offset(
		triDist(pixel_u.x()),
		triDist(pixel_u.y()));
#else
	const vec2r pixel_offset = CauchyDist(pixel_u);
#endif

	const vec3r & cam_pos     = camera.position;
	const vec3r & cam_forward = camera.forward;
	const vec3r & cam_right   = camera.right;
	const vec3r & cam_up      = camera.up;

	const vec3r pixel_x = cam_right * (sensor_width  / xres);
	const vec3r pixel_y = cam_up   * -(sensor_height / yres);
	const vec3r pixel_v = cam_forward +
		(pixel_x * (x - xres * 0.5f + pixel_offset.x() + 0.5f)) +
		(pixel_y * (y - yres * 0.5f + pixel_offset.y() + 0.5f));

	vec3r ray_p = cam_pos;
	vec3r ray_d = normalise(pixel_v);

	// Depth of field
	const real focal_dist = length(cam_pos - camera.look_at) * camera.focal_dist_scale;
	const real lens_radius = camera.lens_radius * camera.dof_amount;

	const real lens_r = std::sqrt(nextSample(pass, dim, pixel_hash)) * lens_radius;
	const real lens_a = two_pi *  nextSample(pass, dim, pixel_hash);
	const vec3r focal_point = ray_p + ray_d * (focal_dist / dot(ray_d, cam_forward));

	ray_p += cam_right * (std::cos(lens_a) * lens_r) + cam_up * (std::sin(lens_a) * lens_r);
	ray_d = normalise(focal_point - ray_p);

	vec3f
		contribution = 0,
		throughput   = 1,
		normal_out   = 0,
		albedo_out   = 0;

	Ray    ray = { ray_p, ray_d };
	int bounce = 0;
	while (true)
	{
		// Do intersection test
		const auto [nearest_hit_obj, nearest_hit_t] = scene.nearestIntersection(ray);

		// Did we hit anything? If not, return skylight colour
		if (nearest_hit_obj == nullptr)
		{
			vec3f sky;
			if (hdr_env && hdr_env->isLoaded())
			{
				sky = hdr_env->sample(ray.d);
			}
			else
			{
				const float height  = 1 - std::max(0.0f, (float)ray.d.y());
				const float height2 = height * height;
				sky = light.sky_up_colour + (light.sky_hz_colour - light.sky_up_colour) * height2 * height2;
			}
			contribution += throughput * sky;
			break;
		}

		// Compute intersection position using returned nearest ray distance
		const vec3r hit_p = ray.o + ray.d * nearest_hit_t;

		// Get the normal at the intersction point from the surface we hit
		const vec3r normal = nearest_hit_obj->getNormal(hit_p);

		const Material & mat = nearest_hit_obj->mat;

		// Resolve base albedo and emission from colouring function or material
		vec3f base_albedo, base_emission;
		if (mat.colouring != nullptr)
		{
			mat.colouring->getMaterial(base_albedo, base_emission);
		}
		else
		{
			base_albedo = mat.albedo;
			base_emission = mat.emission;
		}

		// Output render channels
		if (bounce == 0)
		{
			normal_out = vec3f{ (float)normal.x(), (float)normal.z(), (float)normal.y() } * 0.5f + 0.5f; // Swap Y and Z
			albedo_out = base_albedo;
		}

		// Add emission
		contribution += throughput * base_emission;

		// Add some shininess using Schlick Frensel approximation
		bool sample_specular;
		vec3f albedo;
		if (mat.use_fresnel)
		{
			const real r0 = mat.r0;
			const real p1 = 1 - std::fabs(dot(normal, ray.d));
			const real p2 = p1 * p1;
			const real fresnel = r0 + (1 - r0) * p2 * p2 * p1;

			const real mat_u = nextSample(pass, dim, pixel_hash);
			sample_specular = mat_u < fresnel;
			albedo = (sample_specular) ? 0.95f : base_albedo;
		}
		else
		{
			sample_specular = false;
			albedo = base_albedo;
		}

		// Do direct lighting from a fixed point light
		if (!sample_specular)
		{
			const vec3r light_vec = light.light_pos - hit_p;

			// Compute reflected light (simple diffuse / Lambertian) with 1/distance^2 falloff
			const real n_dot_l = dot(normal, light_vec);
			if (n_dot_l > 0)
			{
				const real  light_ln2 = dot(light_vec, light_vec);
				const real  light_len = std::sqrt(light_ln2);
				const vec3r light_dir = light_vec * (1 / light_len);

				const vec3f refl_colour = albedo * (float)n_dot_l / (float)(light_ln2 * light_len) * (float)light.light_intensity;

				// Trace shadow ray from the hit point towards the light
				const Ray shadow_ray = { hit_p, light_dir };
				const auto [shadow_nearest_hit_obj, shadow_nearest_hit_t] = scene.nearestIntersection(shadow_ray);

				// If we didn't hit anything (null hit obj or length >= length from hit point to light),
				//  add the directly reflected light to the path contribution
				if (shadow_nearest_hit_obj == nullptr || shadow_nearest_hit_t >= light_len)
					contribution += throughput * refl_colour;
			}
		}

		if (++bounce > max_bounces)
			break;

		// Terminate the path unconditionally if the albedo is super low or zero
		const float max_albedo = std::max(std::max(albedo.x(), albedo.y()), albedo.z());
		if (max_albedo < 1e-8f)
			break;

		// Use Russian roulette on albedo to possibly terminate the path after 2 bounces
		if (bounce > 3)
		{
			const float rr_u = (float)nextSample(pass, dim, pixel_hash);
			const float rr_thresh = std::max(0.0f, std::min(1.0f, max_albedo));
			if (rr_u > rr_thresh)
				break;
			throughput *= (1.0f / rr_thresh);
		}

		vec3r new_dir;
		if (sample_specular)
		{
			new_dir = ray.d - normal * (2 * dot(normal, ray.d));
		}
		else
		{
			const real refl_sample_x = nextSample(pass, dim, pixel_hash);
			const real refl_sample_y = nextSample(pass, dim, pixel_hash);

			// Generate uniform point on sphere, see https://mathworld.wolfram.com/SpherePointPicking.html
			const real a = refl_sample_x * two_pi;
			const real s = 2 * std::sqrt(std::max(static_cast<real>(0), refl_sample_y * (1 - refl_sample_y)));
			const vec3r sphere =
			{
				std::cos(a) * s,
				std::sin(a) * s,
				1 - 2 * refl_sample_y
			};

			// Generate new cosine-weighted exitant direction
			new_dir = normalise(normal + sphere);
		}

		// Multiply the throughput by the surface reflection
		throughput *= albedo;

		// Start next bounce from the hit position in the scattered ray direction
		ray.o = hit_p;
		ray.d = new_dir;
	}

	output.beauty[pixel_idx] += contribution;
	output.normal[pixel_idx] += normal_out;
	output.albedo[pixel_idx] += albedo_out;
}


inline void renderThreadFunction(
	ThreadControl * const thread_control,
	RenderOutput * const output,
	const int base_pass,
	const CameraParams * const camera, const LightParams * const light, const RenderSettings * const settings,
	const Scene * const scene_,
	const HDREnvironment * const hdr_env) noexcept
{
	const int xres = output->xres;
	const int yres = output->yres;

	// Make a local copy of the world for this thread, needed because it will get modified during init
	Scene scene(*scene_);

	// Get rounded up number of buckets in x and y
	constexpr int bucket_size = 32;
	const int x_buckets = (xres + bucket_size - 1) / bucket_size;
	const int y_buckets = (yres + bucket_size - 1) / bucket_size;
	const int num_buckets = x_buckets * y_buckets;
	const int num_passes = thread_control->num_passes;

	while (true)
	{
		// Get the next bucket index atomically and exit if we're done
		const int bucket = thread_control->next_bucket.fetch_add(1);
		if (bucket >= num_buckets * num_passes)
			break;

		// Get sub-pass and pixel ranges for current bucket
		const int sub_pass  = bucket / num_buckets;
		const int bucket_p  = bucket - num_buckets * sub_pass;
		const int bucket_y  = bucket_p / x_buckets;
		const int bucket_x  = bucket_p - x_buckets * bucket_y;
		const int bucket_x0 = bucket_x * bucket_size, bucket_x1 = std::min(bucket_x0 + bucket_size, xres);
		const int bucket_y0 = bucket_y * bucket_size, bucket_y1 = std::min(bucket_y0 + bucket_size, yres);

		for (int y = bucket_y0; y < bucket_y1; ++y)
		for (int x = bucket_x0; x < bucket_x1; ++x)
			render(x, y, base_pass + sub_pass, *camera, *light, *settings, scene, *output, hdr_env);
	}
}
